{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(\"C:/Users/suhas/Documents/Mini Project/Leaves/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "num_classes = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(img_name):\n",
    "    num = int(img_name[-8:-4])\n",
    "    if num >= 1001 and num <= 1059:\n",
    "        return 0 #'pubescent bamboo'\n",
    "    elif num >= 1060 and num <= 1122:\n",
    "        return 1 #'chinese horse chestnut'\n",
    "    elif num >= 1552 and num <= 1616:\n",
    "        return 2 #'anhui barberry'\n",
    "    elif num >= 1123 and num <= 1194:\n",
    "        return 3 #'chinese redbud'\n",
    "    elif num >= 1195 and num <= 1267:\n",
    "        return 4 #'true indigo'\n",
    "    elif num >= 1268 and num <= 1323:\n",
    "        return 5 #'japanese maple'\n",
    "    elif num >= 1324 and num <= 1385:\n",
    "        return 6 #'nanmu'\n",
    "    elif num >= 1386 and num <= 1437:\n",
    "        return 7 #'castor aralia'\n",
    "    elif num >= 1497 and num <= 1551:\n",
    "        return 8 #'chinese cinnamon'\n",
    "    elif num >= 1438 and num <= 1496:\n",
    "        return 9 #'goldenrain tree'\n",
    "    elif num >= 2001 and num <= 2050:\n",
    "        return 10 #'big-fruited holly'\n",
    "    elif num >= 2051 and num <= 2113:\n",
    "        return 11 #'japanese cheesewood'\n",
    "    elif num >= 2114 and num <= 2165:\n",
    "        return 12 #'wintersweet'\n",
    "    elif num >= 2166 and num <= 2230:\n",
    "        return 13 #'camphor tree'\n",
    "    elif num >= 2231 and num <= 2290:\n",
    "        return 14 #'japan arrowwood'\n",
    "    elif num >= 2291 and num <= 2346:\n",
    "        return 15 #'sweet osmanthus'\n",
    "    elif num >= 2347 and num <= 2423:\n",
    "        return 16 #'deodar'\n",
    "    elif num >= 2424 and num <= 2485:\n",
    "        return 17 #'gingko'\n",
    "    elif num >= 2486 and num <= 2546:\n",
    "        return 18 #'crepe myrtle'\n",
    "    elif num >= 2547 and num <= 2612:\n",
    "        return 19 #'oleander'\n",
    "    elif num >= 2616 and num <= 2675:\n",
    "        return 20 #'yew plum pine'\n",
    "    elif num >= 3001 and num <= 3055:\n",
    "        return 21 #'japanese flowering cherry'\n",
    "    elif num >= 3056 and num <= 3110:\n",
    "        return 22 #'glossy privet'\n",
    "    elif num >= 3111 and num <= 3175:\n",
    "        return 23 #'chinese toon'\n",
    "    elif num >= 3176 and num <= 3229:\n",
    "        return 24 #'peach'\n",
    "    elif num >= 3230 and num <= 3281:\n",
    "        return 25 #'ford woodlotus'\n",
    "    elif num >= 3282 and num <= 3334:\n",
    "        return 26 #'trident maple'\n",
    "    elif num >= 3335 and num <= 3389:\n",
    "        return 27 #'beales barberry'\n",
    "    elif num >= 3390 and num <= 3446:\n",
    "        return 28 #'southern magnolia'\n",
    "    elif num >= 3447 and num <= 3510:\n",
    "        return 29 #'canadian poplar'\n",
    "    elif num >= 3511 and num <= 3563:\n",
    "        return 30 #'chinese tulip tree'\n",
    "    elif num >= 3566 and num <= 3621:\n",
    "        return 31 #'tangerine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for image in path:\n",
    "    leaf = label(image)\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    # Basic processing\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (3, 3), 0)\n",
    "    thresh, imgBW = cv2.threshold(imgBlur, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    imgInv = cv2.bitwise_not(imgBW)\n",
    "    kernel = np.ones((50, 50))\n",
    "    imgClosed = cv2.morphologyEx(imgInv, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Resize\n",
    "    new = cv2.resize(imgClosed, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    #Adding third dimension to shape\n",
    "    new.shape += (1,)\n",
    "    data.append([new, leaf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([d[0] for d in data])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.divide(X, 255)\n",
    "len(X)\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [d[1] for d in data]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.2),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.2),\n",
    "    layers.Conv2D(64, 5, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    # Flattening output to connect to Densely Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "=================================================================\n",
      "Total params: 1,239,968\n",
      "Trainable params: 1,239,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1430 samples, validate on 477 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 7s 5ms/sample - loss: 3.3884 - acc: 0.1308 - val_loss: 3.3794 - val_acc: 0.1384\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 7s 5ms/sample - loss: 3.3713 - acc: 0.1455 - val_loss: 3.3786 - val_acc: 0.1363\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 8s 5ms/sample - loss: 3.3396 - acc: 0.1783 - val_loss: 3.3600 - val_acc: 0.1530\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 8s 5ms/sample - loss: 3.3166 - acc: 0.2000 - val_loss: 3.3084 - val_acc: 0.2034\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 7s 5ms/sample - loss: 3.2176 - acc: 0.3021 - val_loss: 3.1671 - val_acc: 0.3522\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 7s 5ms/sample - loss: 3.1550 - acc: 0.3636 - val_loss: 3.1602 - val_acc: 0.3627\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 7s 5ms/sample - loss: 3.1321 - acc: 0.3853 - val_loss: 3.1232 - val_acc: 0.3920\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 7s 5ms/sample - loss: 3.0941 - acc: 0.4238 - val_loss: 3.0936 - val_acc: 0.4235\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 8s 5ms/sample - loss: 3.0608 - acc: 0.4552 - val_loss: 3.0824 - val_acc: 0.4361\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0555 - acc: 0.4636 - val_loss: 3.0696 - val_acc: 0.4465\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0354 - acc: 0.4811 - val_loss: 3.0662 - val_acc: 0.4507\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0308 - acc: 0.4860 - val_loss: 3.0676 - val_acc: 0.4486\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0331 - acc: 0.4846 - val_loss: 3.0649 - val_acc: 0.4528\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 8s 5ms/sample - loss: 3.0363 - acc: 0.4818 - val_loss: 3.0719 - val_acc: 0.4444\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0334 - acc: 0.4839 - val_loss: 3.0641 - val_acc: 0.4549\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 3.0303 - acc: 0.4860 - val_loss: 3.0619 - val_acc: 0.4528\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 3.0244 - acc: 0.4930 - val_loss: 3.0573 - val_acc: 0.4591\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0224 - acc: 0.4944 - val_loss: 3.0566 - val_acc: 0.4612\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0210 - acc: 0.4958 - val_loss: 3.0567 - val_acc: 0.4591\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0212 - acc: 0.4951 - val_loss: 3.0548 - val_acc: 0.4612\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 3.0202 - acc: 0.4958 - val_loss: 3.0547 - val_acc: 0.4633\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 3.0121 - acc: 0.5042 - val_loss: 3.0329 - val_acc: 0.4864\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9948 - acc: 0.5210 - val_loss: 3.0426 - val_acc: 0.4738\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.9916 - acc: 0.5259 - val_loss: 3.0313 - val_acc: 0.4885\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9679 - acc: 0.5497 - val_loss: 3.0039 - val_acc: 0.5115\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9568 - acc: 0.5608 - val_loss: 3.0014 - val_acc: 0.5157\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9637 - acc: 0.5545 - val_loss: 3.0125 - val_acc: 0.5031\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9595 - acc: 0.5566 - val_loss: 2.9995 - val_acc: 0.5157\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9541 - acc: 0.5629 - val_loss: 3.0078 - val_acc: 0.5115\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9512 - acc: 0.5664 - val_loss: 3.0105 - val_acc: 0.5073\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9498 - acc: 0.5671 - val_loss: 3.0029 - val_acc: 0.5136\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9473 - acc: 0.5692 - val_loss: 3.0003 - val_acc: 0.5136\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 11s 7ms/sample - loss: 2.9522 - acc: 0.5657 - val_loss: 2.9999 - val_acc: 0.5178\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9506 - acc: 0.5657 - val_loss: 3.0107 - val_acc: 0.5094\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9507 - acc: 0.5671 - val_loss: 3.0064 - val_acc: 0.5115\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9466 - acc: 0.5706 - val_loss: 3.0092 - val_acc: 0.5052\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9438 - acc: 0.5734 - val_loss: 2.9967 - val_acc: 0.5220\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9431 - acc: 0.5734 - val_loss: 2.9975 - val_acc: 0.5199\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9441 - acc: 0.5720 - val_loss: 2.9960 - val_acc: 0.5199\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9430 - acc: 0.5734 - val_loss: 2.9874 - val_acc: 0.5346\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.9396 - acc: 0.5783 - val_loss: 2.9987 - val_acc: 0.5220\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.9410 - acc: 0.5762 - val_loss: 2.9830 - val_acc: 0.5388\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.9231 - acc: 0.5951 - val_loss: 2.9615 - val_acc: 0.5535\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.9107 - acc: 0.6070 - val_loss: 2.9488 - val_acc: 0.5744\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.9039 - acc: 0.6147 - val_loss: 2.9538 - val_acc: 0.5639\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.9002 - acc: 0.6189 - val_loss: 2.9632 - val_acc: 0.5556\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8946 - acc: 0.6231 - val_loss: 2.9599 - val_acc: 0.5597\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8925 - acc: 0.6245 - val_loss: 2.9525 - val_acc: 0.5681\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8898 - acc: 0.6273 - val_loss: 2.9485 - val_acc: 0.5681- loss: 2.8936 - acc: 0.6\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8879 - acc: 0.6301 - val_loss: 2.9519 - val_acc: 0.5639\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8916 - acc: 0.6259 - val_loss: 2.9508 - val_acc: 0.5639\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8904 - acc: 0.6273 - val_loss: 2.9510 - val_acc: 0.5639\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8916 - acc: 0.6266 - val_loss: 2.9577 - val_acc: 0.5597\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8887 - acc: 0.6287 - val_loss: 2.9482 - val_acc: 0.5702\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8852 - acc: 0.6322 - val_loss: 2.9422 - val_acc: 0.5765\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8819 - acc: 0.6357 - val_loss: 2.9440 - val_acc: 0.5723\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8823 - acc: 0.6350 - val_loss: 2.9380 - val_acc: 0.5786\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8809 - acc: 0.6364 - val_loss: 2.9382 - val_acc: 0.5786\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8787 - acc: 0.6385 - val_loss: 2.9411 - val_acc: 0.5765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8759 - acc: 0.6420 - val_loss: 2.9337 - val_acc: 0.5849\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8689 - acc: 0.6490 - val_loss: 2.9422 - val_acc: 0.5765\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8683 - acc: 0.6497 - val_loss: 2.9309 - val_acc: 0.5870\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8734 - acc: 0.6434 - val_loss: 2.9318 - val_acc: 0.5870\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8638 - acc: 0.6531 - val_loss: 2.9254 - val_acc: 0.5912\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8600 - acc: 0.6587 - val_loss: 2.9477 - val_acc: 0.5702\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8572 - acc: 0.6608 - val_loss: 2.9337 - val_acc: 0.5849\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8557 - acc: 0.6622 - val_loss: 2.9492 - val_acc: 0.5681\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8563 - acc: 0.6622 - val_loss: 2.9303 - val_acc: 0.5891\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8504 - acc: 0.6664 - val_loss: 2.9281 - val_acc: 0.5891\n",
      "Epoch 70/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8490 - acc: 0.6692 - val_loss: 2.9309 - val_acc: 0.5870\n",
      "Epoch 71/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8521 - acc: 0.6657 - val_loss: 2.9499 - val_acc: 0.5639\n",
      "Epoch 72/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8594 - acc: 0.6573 - val_loss: 2.9673 - val_acc: 0.5493\n",
      "Epoch 73/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8525 - acc: 0.6650 - val_loss: 2.9307 - val_acc: 0.5870\n",
      "Epoch 74/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8455 - acc: 0.6720 - val_loss: 2.9308 - val_acc: 0.5870\n",
      "Epoch 75/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8435 - acc: 0.6741 - val_loss: 2.9385 - val_acc: 0.5786\n",
      "Epoch 76/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8496 - acc: 0.6678 - val_loss: 2.9262 - val_acc: 0.5891\n",
      "Epoch 77/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8406 - acc: 0.6769 - val_loss: 2.9279 - val_acc: 0.5891\n",
      "Epoch 78/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8401 - acc: 0.6769 - val_loss: 2.9276 - val_acc: 0.5891\n",
      "Epoch 79/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8401 - acc: 0.6776 - val_loss: 2.9270 - val_acc: 0.5933\n",
      "Epoch 80/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8384 - acc: 0.6790 - val_loss: 2.9455 - val_acc: 0.5723\n",
      "Epoch 81/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8464 - acc: 0.6699 - val_loss: 2.9262 - val_acc: 0.5933\n",
      "Epoch 82/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8397 - acc: 0.6783 - val_loss: 2.9296 - val_acc: 0.5870\n",
      "Epoch 83/100\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 2.8295 - acc: 0.6888 - val_loss: 2.9257 - val_acc: 0.5912\n",
      "Epoch 84/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8322 - acc: 0.6860 - val_loss: 2.9402 - val_acc: 0.5744\n",
      "Epoch 85/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8308 - acc: 0.6867 - val_loss: 2.9126 - val_acc: 0.6059\n",
      "Epoch 86/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8272 - acc: 0.6895 - val_loss: 2.9111 - val_acc: 0.6080\n",
      "Epoch 87/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8242 - acc: 0.6944 - val_loss: 2.9019 - val_acc: 0.6143\n",
      "Epoch 88/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8185 - acc: 0.6986 - val_loss: 2.8946 - val_acc: 0.6247\n",
      "Epoch 89/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8232 - acc: 0.6944 - val_loss: 2.9005 - val_acc: 0.6205\n",
      "Epoch 90/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8242 - acc: 0.6937 - val_loss: 2.9131 - val_acc: 0.6038\n",
      "Epoch 91/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8275 - acc: 0.6909 - val_loss: 2.9219 - val_acc: 0.5933\n",
      "Epoch 92/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8261 - acc: 0.6923 - val_loss: 2.9121 - val_acc: 0.6080\n",
      "Epoch 93/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8234 - acc: 0.6944 - val_loss: 2.9089 - val_acc: 0.6101\n",
      "Epoch 94/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8138 - acc: 0.7042 - val_loss: 2.9101 - val_acc: 0.6080\n",
      "Epoch 95/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8074 - acc: 0.7112 - val_loss: 2.9238 - val_acc: 0.5912\n",
      "Epoch 96/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8024 - acc: 0.7161 - val_loss: 2.8889 - val_acc: 0.6289\n",
      "Epoch 97/100\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 2.8046 - acc: 0.7119 - val_loss: 2.9164 - val_acc: 0.5996\n",
      "Epoch 98/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8026 - acc: 0.7154 - val_loss: 2.9076 - val_acc: 0.6101\n",
      "Epoch 99/100\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 2.8053 - acc: 0.7119 - val_loss: 2.9127 - val_acc: 0.6017\n",
      "Epoch 100/100\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 2.8023 - acc: 0.7154 - val_loss: 2.9012 - val_acc: 0.6164\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=epochs, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
