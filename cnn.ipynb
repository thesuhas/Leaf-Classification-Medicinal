{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(\"C:/Users/suhas/Documents/Mini Project/Leaves/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "num_classes = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(img_name):\n",
    "    num = int(img_name[-8:-4])\n",
    "    if num >= 1001 and num <= 1059:\n",
    "        return 0 #'pubescent bamboo'\n",
    "    elif num >= 1060 and num <= 1122:\n",
    "        return 1 #'chinese horse chestnut'\n",
    "    elif num >= 1552 and num <= 1616:\n",
    "        return 2 #'anhui barberry'\n",
    "    elif num >= 1123 and num <= 1194:\n",
    "        return 3 #'chinese redbud'\n",
    "    elif num >= 1195 and num <= 1267:\n",
    "        return 4 #'true indigo'\n",
    "    elif num >= 1268 and num <= 1323:\n",
    "        return 5 #'japanese maple'\n",
    "    elif num >= 1324 and num <= 1385:\n",
    "        return 6 #'nanmu'\n",
    "    elif num >= 1386 and num <= 1437:\n",
    "        return 7 #'castor aralia'\n",
    "    elif num >= 1497 and num <= 1551:\n",
    "        return 8 #'chinese cinnamon'\n",
    "    elif num >= 1438 and num <= 1496:\n",
    "        return 9 #'goldenrain tree'\n",
    "    elif num >= 2001 and num <= 2050:\n",
    "        return 10 #'big-fruited holly'\n",
    "    elif num >= 2051 and num <= 2113:\n",
    "        return 11 #'japanese cheesewood'\n",
    "    elif num >= 2114 and num <= 2165:\n",
    "        return 12 #'wintersweet'\n",
    "    elif num >= 2166 and num <= 2230:\n",
    "        return 13 #'camphor tree'\n",
    "    elif num >= 2231 and num <= 2290:\n",
    "        return 14 #'japan arrowwood'\n",
    "    elif num >= 2291 and num <= 2346:\n",
    "        return 15 #'sweet osmanthus'\n",
    "    elif num >= 2347 and num <= 2423:\n",
    "        return 16 #'deodar'\n",
    "    elif num >= 2424 and num <= 2485:\n",
    "        return 17 #'gingko'\n",
    "    elif num >= 2486 and num <= 2546:\n",
    "        return 18 #'crepe myrtle'\n",
    "    elif num >= 2547 and num <= 2612:\n",
    "        return 19 #'oleander'\n",
    "    elif num >= 2616 and num <= 2675:\n",
    "        return 20 #'yew plum pine'\n",
    "    elif num >= 3001 and num <= 3055:\n",
    "        return 21 #'japanese flowering cherry'\n",
    "    elif num >= 3056 and num <= 3110:\n",
    "        return 22 #'glossy privet'\n",
    "    elif num >= 3111 and num <= 3175:\n",
    "        return 23 #'chinese toon'\n",
    "    elif num >= 3176 and num <= 3229:\n",
    "        return 24 #'peach'\n",
    "    elif num >= 3230 and num <= 3281:\n",
    "        return 25 #'ford woodlotus'\n",
    "    elif num >= 3282 and num <= 3334:\n",
    "        return 26 #'trident maple'\n",
    "    elif num >= 3335 and num <= 3389:\n",
    "        return 27 #'beales barberry'\n",
    "    elif num >= 3390 and num <= 3446:\n",
    "        return 28 #'southern magnolia'\n",
    "    elif num >= 3447 and num <= 3510:\n",
    "        return 29 #'canadian poplar'\n",
    "    elif num >= 3511 and num <= 3563:\n",
    "        return 30 #'chinese tulip tree'\n",
    "    elif num >= 3566 and num <= 3621:\n",
    "        return 31 #'tangerine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for image in path:\n",
    "    leaf = label(image)\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    # Basic processing\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (3, 3), 0)\n",
    "    thresh, imgBW = cv2.threshold(imgBlur, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    imgInv = cv2.bitwise_not(imgBW)\n",
    "    kernel = np.ones((50, 50))\n",
    "    imgClosed = cv2.morphologyEx(imgInv, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Resize\n",
    "    new = cv2.resize(imgClosed, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    #Adding third dimension to shape\n",
    "    new.shape += (1,)\n",
    "    data.append([new, leaf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([d[0] for d in data])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.divide(X, 255)\n",
    "len(X)\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [d[1] for d in data]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.5),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.5),\n",
    "    layers.Conv2D(64, 5, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.5),\n",
    "    # Flattening output to connect to Densely Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 100, 100, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 50, 50, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 50, 50, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 25, 25, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "=================================================================\n",
      "Total params: 1,240,928\n",
      "Trainable params: 1,240,448\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1430 samples, validate on 477 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 12s 9ms/sample - loss: 3.2252 - acc: 0.3224 - val_loss: 3.4736 - val_acc: 0.0356\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 12s 8ms/sample - loss: 3.0192 - acc: 0.5259 - val_loss: 3.4785 - val_acc: 0.0356\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 12s 8ms/sample - loss: 2.9440 - acc: 0.6007 - val_loss: 3.4799 - val_acc: 0.0356\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 12s 8ms/sample - loss: 2.9085 - acc: 0.6273 - val_loss: 3.4819 - val_acc: 0.0356\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 12s 9ms/sample - loss: 2.8734 - acc: 0.6713 - val_loss: 3.4728 - val_acc: 0.0356\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.8130 - acc: 0.7343 - val_loss: 3.4773 - val_acc: 0.0356\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 12s 9ms/sample - loss: 2.7627 - acc: 0.7846 - val_loss: 3.4675 - val_acc: 0.0356\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.7518 - acc: 0.7902 - val_loss: 3.4488 - val_acc: 0.0524\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.7367 - acc: 0.8049 - val_loss: 3.4508 - val_acc: 0.0482\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.7194 - acc: 0.8189 - val_loss: 3.4298 - val_acc: 0.0839\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.6990 - acc: 0.8441 - val_loss: 3.3840 - val_acc: 0.1132\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.6892 - acc: 0.8503 - val_loss: 3.3275 - val_acc: 0.1803\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.6798 - acc: 0.8615 - val_loss: 3.2553 - val_acc: 0.2683\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.6785 - acc: 0.8573 - val_loss: 3.0177 - val_acc: 0.5577\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 15s 10ms/sample - loss: 2.6710 - acc: 0.8643 - val_loss: 2.9259 - val_acc: 0.6478\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 16s 11ms/sample - loss: 2.6647 - acc: 0.8678 - val_loss: 2.8530 - val_acc: 0.7128\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 17s 12ms/sample - loss: 2.6661 - acc: 0.8643 - val_loss: 2.8414 - val_acc: 0.7086\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 16s 11ms/sample - loss: 2.6577 - acc: 0.8720 - val_loss: 2.7998 - val_acc: 0.7463\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 16s 12ms/sample - loss: 2.6523 - acc: 0.8783 - val_loss: 2.7683 - val_acc: 0.7799\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 16s 11ms/sample - loss: 2.6478 - acc: 0.8846 - val_loss: 2.7830 - val_acc: 0.7484\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 16s 11ms/sample - loss: 2.6439 - acc: 0.8888 - val_loss: 2.7892 - val_acc: 0.7505\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 16s 11ms/sample - loss: 2.6336 - acc: 0.8944 - val_loss: 2.7842 - val_acc: 0.7589\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 16s 11ms/sample - loss: 2.6400 - acc: 0.8895 - val_loss: 2.7658 - val_acc: 0.7757\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 15s 11ms/sample - loss: 2.6321 - acc: 0.8979 - val_loss: 2.7517 - val_acc: 0.7904\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 15s 10ms/sample - loss: 2.6246 - acc: 0.9035 - val_loss: 2.7268 - val_acc: 0.8155\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.6170 - acc: 0.9147 - val_loss: 2.7450 - val_acc: 0.7925\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.6242 - acc: 0.9028 - val_loss: 2.7608 - val_acc: 0.7736\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.6171 - acc: 0.9091 - val_loss: 2.7318 - val_acc: 0.8113\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 14s 9ms/sample - loss: 2.6100 - acc: 0.9203 - val_loss: 2.7340 - val_acc: 0.8050\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.6042 - acc: 0.9217 - val_loss: 2.7543 - val_acc: 0.7862\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.6024 - acc: 0.9266 - val_loss: 2.7313 - val_acc: 0.8050\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 14s 9ms/sample - loss: 2.5979 - acc: 0.9315 - val_loss: 2.7430 - val_acc: 0.7862\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.6038 - acc: 0.9252 - val_loss: 2.7319 - val_acc: 0.8050\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5937 - acc: 0.9357 - val_loss: 2.7452 - val_acc: 0.7841\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5907 - acc: 0.9343 - val_loss: 2.7255 - val_acc: 0.8113\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.5869 - acc: 0.9413 - val_loss: 2.7319 - val_acc: 0.8008\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.5867 - acc: 0.9385 - val_loss: 2.7296 - val_acc: 0.7966\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 2.5854 - acc: 0.9406 - val_loss: 2.7152 - val_acc: 0.8050\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 14s 9ms/sample - loss: 2.5836 - acc: 0.9413 - val_loss: 2.7147 - val_acc: 0.8113\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5782 - acc: 0.9448 - val_loss: 2.7262 - val_acc: 0.8050\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5787 - acc: 0.9441 - val_loss: 2.7255 - val_acc: 0.8008\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5762 - acc: 0.9476 - val_loss: 2.7187 - val_acc: 0.8092\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5742 - acc: 0.9483 - val_loss: 2.7065 - val_acc: 0.8302\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5744 - acc: 0.9517 - val_loss: 2.7277 - val_acc: 0.8029\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5753 - acc: 0.9497 - val_loss: 2.7172 - val_acc: 0.8134\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5720 - acc: 0.9510 - val_loss: 2.7216 - val_acc: 0.7987\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5733 - acc: 0.9483 - val_loss: 2.7285 - val_acc: 0.7966\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5723 - acc: 0.9510 - val_loss: 2.7120 - val_acc: 0.8260\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5727 - acc: 0.9503 - val_loss: 2.7386 - val_acc: 0.7862\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5699 - acc: 0.9531 - val_loss: 2.7115 - val_acc: 0.8218\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5712 - acc: 0.9517 - val_loss: 2.7356 - val_acc: 0.7987\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5684 - acc: 0.9559 - val_loss: 2.7446 - val_acc: 0.7841\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5648 - acc: 0.9580 - val_loss: 2.7276 - val_acc: 0.7987\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5649 - acc: 0.9587 - val_loss: 2.7190 - val_acc: 0.8092\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5637 - acc: 0.9594 - val_loss: 2.7146 - val_acc: 0.8113\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5580 - acc: 0.9636 - val_loss: 2.7110 - val_acc: 0.8155\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5580 - acc: 0.9636 - val_loss: 2.7151 - val_acc: 0.8113\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5578 - acc: 0.9650 - val_loss: 2.7024 - val_acc: 0.8365\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5592 - acc: 0.9629 - val_loss: 2.7007 - val_acc: 0.8344\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5592 - acc: 0.9636 - val_loss: 2.7104 - val_acc: 0.8239\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 15s 10ms/sample - loss: 2.5572 - acc: 0.9657 - val_loss: 2.7194 - val_acc: 0.8050\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5530 - acc: 0.9685 - val_loss: 2.7114 - val_acc: 0.8197\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5533 - acc: 0.9699 - val_loss: 2.6997 - val_acc: 0.8407\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5494 - acc: 0.9734 - val_loss: 2.6998 - val_acc: 0.8344\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5530 - acc: 0.9699 - val_loss: 2.6963 - val_acc: 0.8449\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5511 - acc: 0.9734 - val_loss: 2.7009 - val_acc: 0.8281\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5513 - acc: 0.9706 - val_loss: 2.6901 - val_acc: 0.8428\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5496 - acc: 0.9713 - val_loss: 2.7037 - val_acc: 0.8323\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5518 - acc: 0.9706 - val_loss: 2.6857 - val_acc: 0.8470\n",
      "Epoch 70/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5511 - acc: 0.9713 - val_loss: 2.7134 - val_acc: 0.8176\n",
      "Epoch 71/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5457 - acc: 0.9755 - val_loss: 2.7099 - val_acc: 0.8218\n",
      "Epoch 72/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5476 - acc: 0.9755 - val_loss: 2.6940 - val_acc: 0.8344\n",
      "Epoch 73/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5493 - acc: 0.9699 - val_loss: 2.6984 - val_acc: 0.8281\n",
      "Epoch 74/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5453 - acc: 0.9769 - val_loss: 2.7054 - val_acc: 0.8218\n",
      "Epoch 75/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5502 - acc: 0.9713 - val_loss: 2.6945 - val_acc: 0.8344\n",
      "Epoch 76/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5458 - acc: 0.9762 - val_loss: 2.6936 - val_acc: 0.8407\n",
      "Epoch 77/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5459 - acc: 0.9762 - val_loss: 2.6982 - val_acc: 0.8302\n",
      "Epoch 78/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5507 - acc: 0.9720 - val_loss: 2.6937 - val_acc: 0.8386\n",
      "Epoch 79/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5452 - acc: 0.9748 - val_loss: 2.6892 - val_acc: 0.8344\n",
      "Epoch 80/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5439 - acc: 0.9769 - val_loss: 2.6911 - val_acc: 0.8281\n",
      "Epoch 81/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5451 - acc: 0.9755 - val_loss: 2.7139 - val_acc: 0.7966\n",
      "Epoch 82/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5443 - acc: 0.9762 - val_loss: 2.6954 - val_acc: 0.8344\n",
      "Epoch 83/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5431 - acc: 0.9769 - val_loss: 2.6874 - val_acc: 0.8386\n",
      "Epoch 84/100\n",
      "1430/1430 [==============================] - 15s 11ms/sample - loss: 2.5414 - acc: 0.9776 - val_loss: 2.6922 - val_acc: 0.8365\n",
      "Epoch 85/100\n",
      "1430/1430 [==============================] - 15s 11ms/sample - loss: 2.5410 - acc: 0.9783 - val_loss: 2.6902 - val_acc: 0.8407\n",
      "Epoch 86/100\n",
      "1430/1430 [==============================] - 15s 10ms/sample - loss: 2.5412 - acc: 0.9790 - val_loss: 2.7027 - val_acc: 0.8260\n",
      "Epoch 87/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5403 - acc: 0.9804 - val_loss: 2.6985 - val_acc: 0.8239\n",
      "Epoch 88/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5422 - acc: 0.9783 - val_loss: 2.6982 - val_acc: 0.8344\n",
      "Epoch 89/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5410 - acc: 0.9790 - val_loss: 2.7070 - val_acc: 0.8218\n",
      "Epoch 90/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5402 - acc: 0.9797 - val_loss: 2.7030 - val_acc: 0.8176\n",
      "Epoch 91/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5413 - acc: 0.9790 - val_loss: 2.7023 - val_acc: 0.8281\n",
      "Epoch 92/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5437 - acc: 0.9783 - val_loss: 2.7012 - val_acc: 0.8260\n",
      "Epoch 93/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5413 - acc: 0.9790 - val_loss: 2.6920 - val_acc: 0.8260\n",
      "Epoch 94/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5404 - acc: 0.9797 - val_loss: 2.6892 - val_acc: 0.8365\n",
      "Epoch 95/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5400 - acc: 0.9797 - val_loss: 2.6932 - val_acc: 0.8365\n",
      "Epoch 96/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5426 - acc: 0.9776 - val_loss: 2.7043 - val_acc: 0.8218\n",
      "Epoch 97/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5436 - acc: 0.9755 - val_loss: 2.6948 - val_acc: 0.8281\n",
      "Epoch 98/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5415 - acc: 0.9797 - val_loss: 2.6960 - val_acc: 0.8260\n",
      "Epoch 99/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5401 - acc: 0.9797 - val_loss: 2.6880 - val_acc: 0.8302\n",
      "Epoch 100/100\n",
      "1430/1430 [==============================] - 14s 10ms/sample - loss: 2.5389 - acc: 0.9804 - val_loss: 2.6899 - val_acc: 0.8407\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=epochs, validation_data = (X_test, y_test), callbacks=[tensorboard_callback], use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2647128ce88>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7T0lEQVR4nO3deXhU5dn48e+dfQMCJAQIhDXsOwFZFBFccMUdsLZuLUWt62tbrbbVt/XVWuquIFpUqj9Qq7ggKiqbsihh3/eQBEI2kpB9m+f3x5mEBJIwQGbOJHN/rivXzJw5c+Y+ITz3Oc8qxhiUUkr5Lj+7A1BKKWUvTQRKKeXjNBEopZSP00SglFI+ThOBUkr5uAC7AzhTUVFRpmvXrnaHoZRSTcr69euzjDHRdb3X5BJB165dSUxMtDsMpZRqUkTkUH3vadWQUkr5OLclAhGZKyIZIrKtnvdFRF4WkX0iskVEhrkrFqWUUvVz5x3BO8CkBt6/HIh3/kwHZrkxFqWUUvVwWyIwxqwEjjWwy2RgnrGsBSJFpIO74lFKKVU3O9sIYoGUGq9TndtOISLTRSRRRBIzMzM9EpxSSvkKOxOB1LGtzhnwjDFzjDEJxpiE6Og6ez8ppZQ6S3YmglSgc43XnYAjNsWilFI+y85xBJ8DvxORBcB5QJ4xJs3GeJRSzV1lBZQVQFmh8ycfCrOgIN36CW4FbbtDmx4QGOrcpwBKC048x0BQBASFOx+dz/0CTjp2gfVTXnLi+/0DILILtOkOYW1Oja8wGw6tgvJi5wYD5UUnjtlpBPSc2Oi/FrclAhGZD4wHokQkFfgrEAhgjJkNLAauAPYBRcAd7opFKeVkjPXj53fqdkelVVCdCYcDjm6BpB+hwll4iR90GQudzwNx1gCnrIOf34CQSBhyC3Qcam3P2AE7PofcGmOdItpBz4uh8ygICIKyImu/jJ1wbD9k74eiYxAeBRExEBppFZynFMLO56UFJ15Xlp7Nb809QiKhbQ8rKUTEQPIaOLyBemrILec/5JZEIE1tYZqEhASjI4uVOg1jrMKyIB0KjkL6dji0xipsKkqsK8suYyCsrbXt0Bpr3+je0H6QVUBVlFqFZ0UJBIZBcAQEBFtXuGWFUJgJB1dYn6tL254w4EZIXg0HV0JIK+uYFSXQrj9UlkH2XitxtOxktRoaID8NHOUQ1AJadoDsfWAc1jH9AqF1VysJFGZBQQaU5kFAqPMKPcz6XFC49RPsvGKviv/k50ERzoTSDsKjoSTPSjTHDljxBdc4VtVxAcprJpgi687CUVlj3xr7B4ae+J1UlFpJL3u/ldSOHYDsA5B/xEqOPS+BHhNq3y0Ehp04pp//Wf9JiMh6Y0xCne9pIlDKSzkqoSjbKmgLs6yCqk13q7CrYoxVcB47YBUuGTsgbQukb4PS47WP17qbVfgHhVuF/9FtgIEWHSBuNETGWZ8/utU6pvhZBWVA8IkrbgDE2h7S0rrqj68qvNpab5cXwc5FsPE9KwlEtIcx98Hw28FRAds+hi0fWMftNxn6XmMVxFVK863EsfdbK9nE9LeSU0x/aNX51LsWh+PUO5ymxpgTd09uoolAKW9jjHXFWVpgXQ3uXwb7voXktdb2hkS0t64Mq65ITeWJ9wLDof2AE1f1ETHQor2VQFq0r32ckjzrp1XnUwuhilLwD6q93eGwYgsIdr3QKsiw7gQCgl3bX7lNQ4mgyU06p1ST4KiEIxsh5ecTVQB5h080IJYVWlfHNbXrDyN+bVVHACAnqi1C20BhhlWNkHPQei/Y2UjZsqNV0LfpAa06uV59ENLK+qlLXQW3nx/4hbj6G7DUvNJXXksTgfI9pQWQ+jMc2WRVZ7TpbtU7V5RA/lGrOqJFe4gZYFV/GAPHj1hVJuVFJ3qJFGZaDaVHt0LJcavQa9HeqpvfvxSKnQPrq3qiRPeG4JZWAV6znjokErqOtQpxpWygiUA1HzWrMxyVVgNp8hpI22xVgZQVWHXu6TtqV6c0pHU3q669KLvu98UfovtYjXuZu6zGU/8giL/UqjvveoGVINxc/6vUudBEoLxT9n6rfjmmv3VVDs6eMNlWQ2ZVt8C8lBO9XvKSqW7INA6rZwdY9eRhUdZVfEQMxF8GXUZDbIKVII7th5wkq369RYzVKJuX6rza32ZdubcfDB0GWVfvZQVWg2ZIK2jXDwLPsLpEKS+jiUDZq7TAqm4Ja2vVbR/ZCD88Dzu/oLo/detuVqF77KDVVfBk4dFWr5dhv7QaM8sKrUTQcZhV4EfG1f/9oZHQusup22P6Q6/LGuMMlfJ6mgiU+zkckLHdGlFZdXUPVjfCLx6yCnfxt6pXCjOtOvVxj1hX7Olbre6QVaMq23SHVrHO/t3OPuCtu2nVi1LnQBOBcg+HA1J+gh2fwo7PrOqcoAhrVOmQX8BPb8Dm/2cV7gNvPjHEPyoeht9xImH0bmhJC6VUY9BEoBpHRalVp59zEHZ9eaLw9w+2Gk17XQaHVsP6d+DnOdZgpXF/gAv/AP6BdkevlE/TRKDOzZYPYckTtacZqCr8+11rXdFX9Ysf9iu45H9h+0JrOH3nkbaErJSqTROBqt+Wj6zRrpf8zepNU1N5CXz9R+sKv9NIGPEbq5tky44QN6rGoKiTRLSD837r9tCVUq7TRKBOVbOQBzj4A0x9H2KHWV04k36Abx63uleOfRAm/PnMZ61USnkN/d+rTjDG6r75xQNWIX/+Q9akYB/8CuZOglEzrInAMnZY/fKnfaCNuUo1A5oIFBTnwKb5sOl9a9bKkMjahfz0ZfDR7bDqJWsys8mvw4AbdCCVUs2EJgJfUZpvTQ1sHND7cqvPfmU5rPs3LH8GSnIhdjhc+bxVyIdGnvhseBT88lNr4rSoeO2zr1Qzo4mgOasos+aD3/IhbP/0xJQLfgHQfTzkHLIWBuk+3moQ7jCo/mP5B0B0Lw8ErZTyNE0EzU1ZEWz/BHYttiZAKyuwVkoaeAMMudXqs181yCsg1KoC6nWZXuUr5cM0ETQXucmw7i3YMM+q828VB4Nutpa+637hiSX2wOr9c8n/2herUsqraCJoyoyxFg3/aTbsXmxt63MVnDfDWpJQr/KVUi7QRNAUGWMV/MuesSZlC20NYx+AhLsgsrPd0SmlmhhNBN7I4bAaeZNWWY/pO6zVreJGQ9ue8PMbcHi9tTTh1S9bVUCBoXZHrZRqojQR2Cn5J9j5uTUDZ4+LrOULt/4XfnwBsnYDYs2L32MCZO6EH2Za3T9bdoJrXoHBt+iIXqXUOdNSxA7GwOpX4LsnrYIdY83HH9oairKstXKvf8uauK1mf/6S45C5G9oP1MFcSqlGo4nA0wqz4PP7YfeX0Pdqq2oncxfs+w6y91lz9cdfWndDb0hL6DzC8zErpZo1TQSekrYZfpoDWz+yFk6/7BkYdbdV4HcZY/0o5UGVDkNxeSURwa4VA5n5pXy8IZVfje5CWJAWHc2J/mt6wrL/gxX/sNoAhv7C6t4Z3dvuqJSPyC4opbi8kk6tw6q37cvI5/75mziSV8x/Z4yhZ7uI6vcSk47x8YZU7psQT8dIqxNCZn4p095cy76MAioqHfxuQnyjxZeWV0xwgD9twoMa7Zj1KatwcDCrkB7R4QT4+7n9+xrT2gPZ9IiOILpFcKMfW4wxjX5Qd0pISDCJiYl2h+G6zD0wa7TVv//ql2rX+SvloqW70vEToVtUOLGRoS4XYoWlFVzx8g8cyi7iot7R3DamKyk5xfx90Q7CgwMQIDTIn4X3jCW6RTA/HcjmjnfWUVRWSavQQJ65fiAjurZh2ptrOZxTTPfocFJzivnxjxfRIuTsV5YzxrBqXzbvrD7I97syCAv056nJA7hhWCwiwrHCMl7+fi970vMZ2zOKC3tF079jS+Q0Y2NKyitZcyCb5bsy2JSSS1REMF2jwoluEcyGQzms2pdFYVklF/aK5o1fDick0P+sz8EVOYVlfLcznUqHVc5GhgVyab/2+Pm5PsanrMLBC9/tYfaK/dwyMo6nrxt4VrGIyHpjTEKd72kicCNj4L0bIDUR7lsPEdF2R+TzKh0G/zP4T+gNlu5K5853TvzNB/oLt4yM47Er+p62IHv04y18kJjCL0d1YfHWo2QVlAIwrlc0M28axNG8Eqa8sZb4mAgevqQX97y/gQ6tQvjHDYP425c72ZySS+uwQErKHbx9xwjCgvy55tVVPHJprzrvCjan5PLQh5vo1a4Ft43pyqjubU4pvDOOlzDjvfVsSM6lbXgQU0d2Zt3BHH5OOsZVgzowpHMkL3+/l4LSCnpER7A3owCA2MhQbjkvjmkj4+q8e9iamse0N9dSUFpBSKAfQzpHkltUTlJ2ISXlDmIjQ7mwdzRR4UG8smwf4+LrTga7j+bzh4+30D0qnGeuH3jWyeLHvVn8z0ebSD9eWmv7lITOPHP9QJeSwYHMAh5YsImth/OYNrIzf76q31lXy2kisMvur2D+VKs9YPQ9dkfj81bvy+Lu9zfw8rShXNjrzJNyXlE5QQF+hAa59yqyptKKSi57YSX+fsIz1w8iKbuQxKRjfJiYSq+YCF6aOpS+HVrW+dlvd6Tzm3mJzLiwB49e3oeyCgdfbUsD4OpBHasLou92pDP9P4k4DPRsF8H/+815tGsRQnmlg5e+28t/16fy4tQhjOreFoC73llH4qGcU+4Kvt6WxoMfbCIyNIiSikpyi8rp074Ft4/pyuQhsYQG+bPr6HHufHsducXl/OWqflw3LJbgAH8qHYbZK/bzwrd7qHAYLoiP4okr+9G7fQsy8ktYsTuTTzcdZtW+bIIC/LhlZBx/uapfrcL0wQUb+X5XBq/eMozzurWpLsCNMeQWlRMZFlidlD5cl8IfP9nCuPhonrtxEO2c1S3z1hzi6cU7CQ3053hJOUM6R/LmrxKIiqhdHWOM4fPNR0hMyiGuTRhdo8KJaRmMn/P4n28+wpyVB+gRHc5zNw6qrmJ7b+0hXlu2vzoZiMDaA8dYvDWNyLBAurQNp0OrEDal5LJsVwYbU3JpERLAs9cPYtKA9uf0t6SJwA4VpfDaeeAfBHev0gXabZZXVM5lL67k6PESesVE8NUD487ozqCswsHFz6+gf8eWzLp1eK33Mo6XUFLuIK5tWD2fPnuzV+zn2a92Me/OkYyrkbxW7MnkkY82k1dUzsybB3PN4I61Y8ovYdKLP9C+ZQif3juWoICGq5I+TExh0ZY0Zt40iHYtGu6avCU1t9ZdQX5JOfPWHGLmkt3VBWdEcACfbTrM26uS2HU0n1ahgVw1qAOfbTpCeLA//75tBANiW51y7O1H8sgtKmdMj7Z1VgPtSc9n1vL9LNx4mLd+lcDF/awlVPOKyhn5f99xU0In/n6ta1UnVcnAGAgLstooUnOKuah3NM/dOJj1h47x4AebiIoI5sUpQxgW1xo/PyGvqJw/fbqVL7ekERroT3F5ZZ3Hv3VUHI9f0a/WhYMxhue/3cMrS/dxcd92pOYUs+toPqGB/pRWVOKoURwPiG3J+F7tuHVUF9q3Ovfu4poI7LD077Dyn/DLhdaAsCbEGHPautimxBjDffM38vW2o0wf153Xl+/nuRsHcXOC69NxvP/TIR5fuI0AP+GnP02kbY0rxOtfX8XBrEK+/5/xjdrgmX68hAkzlzO6RxRv3Xbq/9/sglJmvLeeLal5fHz3mOqCtaS8krveXUdiUg6L7juf+Jh61o8+B79+dx0/HzxG3w4tWX8ohwqH4cqBHfjXzYNrVaUYY/j54DHeWZ3Ekh3p9IppwdzbE+jQ6uxHwpdXOhj/z+V0aBXCf++2etvNW5PEXz7bzqL7zq8zwdRnS2oum1JyOZhVSMqxYi7sHc2t58VV//1vTsnl1/MSycwvJSoiiHHx0aw9kE1GfikPX9qL347rQX5JOUnZRWTmn6gCimkZzKBOkXV+pzGGF77dw8tL99G3Q0vuGNOVa4Z0xE+E1JwijuSW0Kt9xGkT8pnSROBJxlgJYNnTMGgqXP+G3RGdkdkr9vPF5iMsmD6qwcbAwtIKwl3sduiq0opKAvz8XL5Sr3QYSisqT1tn+unGwzz4wSZ+f1lv7hnfg2tfX03G8RKWPTKekEB/isoqmLfmEJf0i6FHdMQpny+rcDD+n8sI8Pcj+VgRf726H3eM7QbAtsN5XPXKjwBcPzSW56cMOaNzLq90sDe9gBV7Mlm+O4Oth/MYENuK8b2j2ZySy7JdmXz78Di6tA2v8/NZBaVc9fKPBAYIi353AcGBfsx4bz3Ld2cy86bB3Di80xnF46pth/O4ftZqukeFM753Oy7qHc3Ibqe2B5wca4uQAIIDzr1q7d3VSfz18+18NGM0I7q24YqXfkAEvrz/gnM+9snyisr5flc6y3dnsnJvJm3Dg3j+5iEM7hx5TsdNyyumfcsQj1102ZYIRGQS8BLgD7xljHn2pPdbAe8BcVhdWWcaY95u6JhenQiMgW//AqtfhsHT4JpXm9QUEElZhVz6wkrKKh3cNroLT00eUOd+3+1I59fzEhnbsy23je7KxL4x59wAW+kwTH7tR/JLKnhp6lCGNPCfLK+onA8TU5i3Nom03BImDWjP7WO6MrxL61P+U63en8Vv562nd/sWfPDb0fj7CWv2ZzPtzbU8dnkfxvSI4oEFGzmQVUhURBDzfzPqlCvoqruBd+8cyT+/2QXAovusAufRj7fw6abDTB0Rxzurk3j3zpGnbX9YvT+LOSsPcCCzkMO5xdU9Svp2aMmQzq3YnJLHjrTjANwzvgd/mNSnweNtSM5hyhtrGNszCoDluzP5xw0DmTIirsHPnSuHw5xR75fGVFxWydh/LGVI50gevqQXV73yI3+b3J9fju7q1u9tynfLDSUCt5VSIuIPvAZcAqQC60Tkc2PMjhq73QvsMMZcLSLRwG4Red8YU+auuNzGGFj8e1j3pjUL6BUzwa9p9VP++5c7CfQXJg3oyLy1h7hmSCzDu7Q+Zb931yTRJjyIA5mFTP/PeuLahDH39gR6tjtRgB4rLOOxT7Zwx9hu1Y2MYF31/+mTbVzUJ5qrBp2o1/54QyrbDh+nVWggN8xazUMXx3P3+J61EszxknJeXbqP/6w5RHF5JSO7tmFC73Ys3HiYRVvS6NO+BZf2i+HC3u1oHRbIs1/tYsmOdGIjQ3lhypDqY43u0ZbxvaN56fu9zFyym6iIYP554yCe+2Y3095cWysZlFU4eG3pPobGRTIuPor9GZ3430U72H00n/atQvhs0xEmD47l0cv7sHJvJo8v3MqSh8bVeZdSVuHgX9/uZs7KA3RsFcrQuEgmD+lI9+hwxvSIIqbliaqAjOMlbErJZXzvdqf9dxsW15q/XNWPP3+2HcAjSQCwLQmA1eX19jFdef7bPZSUVxIc4Mc1Q2Ld/r1NNQmcjtvuCERkNPCkMeYy5+vHAIwxz9TY5zGgM1ZC6Ap8C/QyxjjqO65X3hEYA4sfsRaGGXOftexjE/uDWbEnk9vm/syjl/fh1lFduOT5FbQICWDRfRfUamhMzSnigueWcf+EeO6b0JMlO9L586fbiAwL5LPfnU9EcACVDsNtc3/mx31ZtA4LZNH9FxDr7DXx+MKtvP9TMiGBfnx5/wX0iI6gpLySi2Yup13LEObdMZInPtvGF5uP0D06nIv7xjC+VzQHswt5fskejhWVcd2QWO66oBv9O1p1wUVlFSzceJhPNhxmY3JOdYNbWJA/917Uk7vO73ZKF8Cdace59rVVTOzbjv+7biCRYUHsyyhg2ptrMcbw4MW96B4VzubUPP7x9a7qK/2sglJG/d/33HV+N9q3CuGpL3ZU10v/dCCbKXPWcufYbvzl6n61vi/lWBF3v7+ebYePc8t5cTxxZd9GHZ1rjGHWiv3EtQmrlWCbs9yiMsY8u5SiskquGxrLC2dYLedrbKkaEpEbgUnGmF87X/8SOM8Y87sa+7QAPgf6AC2AKcaYL+s41nRgOkBcXNzwQ4cOuSXms1IrCdxvrfzVxJJAWYWDSS+txOEwfPPQOIID/Pl+Zzp3vZvI/1zSi/smnugvbjVy7eWHP1xUPVJ19f4sbn3rJy4f0IFXbxnKzCW7eW3Zfu6f0JO3VyXRPTqcD2eM5ovNaTzy0WamjezMV9uOEtcmjI/vHsPcHw/yzFe7WDB9FKO6t8UYwxdb0vhgXTI/HzxGeaX1NzqyWxv+clW/BhsDc4vKWLk3i0NZhUwZ0Zl2LetvcCsuqzylK+i+jAJum/szh3OLq7cNjYvkk7vHVF8N/vrddWxJzaNFSAARIYF8du/Y6n2f+HQr761N5vEr+vKbcd0Bq8pt2ptrKSqr5LkbB3FZ/3PrBqhO+NuiHfz7x4PM/80oRvdoe/oP+DBbqoaAukrDk7POZcAmYALQA/hWRH4wxhyv9SFj5gBzwLojaPxQz4Ix1poAq1+x1gBuokkArAbiA5mFzL09obohb2LfGK4c1IFXlu5jXK9oBneOpNJh+CgxhQvio2tNVzCmRxR/nNSHZ77aBfPhyy1pTB3RmYcv7U2/jq2Y8d567n1/Iz/szWR097b8bfIALoiP5p73N/D0lzv5ZEMqF/WOrq5CEhGuGdyRawZ3pLC0gjX7swkM8GNcfNRpb80jw4JO6UpZn7rGA/RsF8EPf7iItOMlJGUVknys6JSujDcM68R3OzPIyC9l5k2Da33+r1f3J6ewnKcX7wTgkn4xTHtzLSXllSyYPqrePv/q7Dx0SS+Gd2nNqO5t7A6lSXNnIkjFqvap0gk4ctI+dwDPGuu2ZJ+IHMS6O/jZjXGdu20fw/J/WGsGBITC+Mfgwj82ySTw9qqDPP/tHq4e3JEJfWJqvff3yQPYlJzLPe9v4Iv7zmdLai5H8kp4/Mp+pxxn+rjubEzO5cstaQyMbcWT1/QHYNKA9sy4sAezV+ynfcsQXrllKAH+flwxsAM3DOvEO6uTEKHeBtHw4IDqvuKe4ucnxEaGEhsZytg63p/Qtx0tQwIQEa4a1KHWe4H+frw4dQgATy/eyStL9+LvJ/y/32gScIeI4ACuGNjh9DuqBrkzEawD4kWkG3AYmArcctI+ycBE4AcRiQF6AwfcGNO5KyuCT++B1t2sKaT7X2dND22zD9elMKJbG7pF1d3NsC5vrzrIU1/s4LL+MTx/8+BT3m8dHsSsW4dx46w1PLBgY/Wgm4v7ndqAKSL886ZBxMdEMG1kXK06+Ucu7UV4kD8T+8bUGqH55DX92JKay+gebZtUIRkc4M8z1w/C3486px+oSgb+fsLq/dn8566RTer8lO9xd/fRK4AXsbqPzjXGPC0iMwCMMbNFpCPwDtABqyrpWWPMew0d0/bG4t1fw/wpXjVQrKov+wXxUfznrvNc+kzVAJzL+sfw6i3DCGxgErP5Pyfz2CdbAfj1+d144qpT7wjOVqXD4CfNtzdGRaWjyc1yqZonu9oIMMYsBhaftG12jedHgEvdGUOj2/sNBIZDl7oqDewx98eDAPywN4ttzgFJDflqaxp//Xw7l/Q7fRIAmDqiMxuTc/h4w2GmjHB9NK4rmtoEcGdKk4BqCvSv9EwYA3uWWOsLBzT+nOBnI+N4CV9sOcL1w2KJCA5g9or9De5fNX/K0M6RvDJt6GmTAFhX689eP4gVvx/vlukKlFL20kRwJjJ2wvFUay1hL/He2kNUOAz3T4jnF6PiWLw1jaSswjr3PZhVyK/fTaRjZChv3TbijKbX9fOTWj2FlFLNhyaCM7H3G+sx3jtqs0rKK3nvp2Qm9omha1Q4d43tRoCfH3N+qN3eXl7pYO6PB7n2tVX4ifDOHSM8shqUUqppaDoT4XiDPUug/UBo6R0jNz/bdJhjhWXceX5XANq1DOGG4Z347/pU7hzblfySCvamFzB7pTVO4IL4KP56df96JzBTSvkmTQSuKs6BlJ/g/AftjgSwphSY+2MSfdq3YHSNuXymj+vOgnXJXPz8yupt3aPC+fdtCUzo067Z9s5RSp09TQSu2r8UTCXEX2Z3JAAkHsphd3o+z90wqFbh3i0qnBenDCEzv5SubcPpGhVO17Zh2ntFKVUvTQSu2rMEQltDpzq74Xrcgp9TiAgO4KrBp46qnOyBWRiVUs2HXia6wuGAfd9Bz4vBz3Pr1dbneEk5i7emcfXgjo06g6VSyjdpInBF9l4oyoJuF9odCQBfbD5CcXllow/uUkr5Jk0ErkheYz3GjbY3DqcP1qXQp30LBndyfW1WpZSqjyYCVySvhbAoaNvD7kjYceQ4W1LzmDKis/YAUko1Ck0ErkheC3GjbJlmuqLSwTurDvLj3ixKKyr5MDGFIH8/rtUGYaVUI9GWxtPJPwo5B2HEXbZ8/Yo9mTz5hbXMc2igPw5juGxAe1rryGClVCPRRHA6yWutR5vaB9YfyiHAT3j1lmGs3p/FxuRcfnNBN1tiUUo1T5oITid5rbUKWftBtnz9+kM59O/YkkkD2jNpgK51q5RqfNpGcDopayF2OAR4viqmvNLB5tRchnVp7fHvVkr5Dk0EDSktgLQtVkOxDXamHaek3MFwTQRKKTfSRNCQw4nW/EI2tQ9sOJQDoIlAKeVWmggakrwWEOg8wpavX5+cS4dWIXRoFWrL9yulfIMmgoYkr4WYARBizwjeDYdytH1AKeV2mgjqU1kOqesg7jxbvj4tr5jDucUMj9NEoJRyL00E9Tm4EsoKoMcEW75+w6FcQNsHlFLup4mgPjs+haAW0GOiLV+//lAOIYF+9OvY0pbvV0r5Dk0Edaksh51fQO/LITDElhDWJ+cwqFMkgbqymFLKzbSUqcvBldYaxf2vteXrS8or2XEkT6uFlFIeoYmgLjZXC209nEd5pWGYNhQrpTxAE8HJvKBaaNfRfAAGxGr7gFLK/TQRnMzmaiGAfen5RAQH0L6lPYlIKeVbNBGczOZqIYC9GQX0aBehK5AppTxCE0FNFWW2VwsB7MsoIL5dhG3fr5TyLZoIalr/jlUtNHiqbSHkFZWTkV+qiUAp5TGaCKqU5MGKZ6HbONtGEwPsy7QaiuNjNBEopTxDE0GVH1+Aomy45G+2LFJfZW96AQA9o1vYFoNSyre4NRGIyCQR2S0i+0Tk0Xr2GS8im0Rku4iscGc89cpNgTWvw6Cp0HGILSFU2ZdRQEigH7GtdepppZRnuG3NYhHxB14DLgFSgXUi8rkxZkeNfSKB14FJxphkEWnnrngatPTv1uOEJ2z5+pr2ZhTQIzoCfz/tMaSU8ozT3hGIyFUicjZ3DiOBfcaYA8aYMmABMPmkfW4BPjHGJAMYYzLO4nvOzbGDsGUBjLobIjt7/OtPti+jgJ7aUKyU8iBXCvipwF4ReU5E+p7BsWOBlBqvU53bauoFtBaR5SKyXkR+VdeBRGS6iCSKSGJmZuYZhOCClJ+tx0FTGve4Z6GwtILDucXaY0gp5VGnTQTGmFuBocB+4G0RWeMsmE/XmllX3YY56XUAMBy4ErgM+LOI9KojhjnGmARjTEJ0dPTpQj4zaZshIBSiTvlaj9uf6WwobqcNxUopz3GpyscYcxz4GKt6pwNwHbBBRO5r4GOpQM26lk7AkTr2+doYU2iMyQJWAoNdjL1xpG2G9gPA323NJS6r6jGkXUeVUp7kShvB1SKyEFgKBAIjjTGXYxXYjzTw0XVAvIh0E5EgrCqmz0/a5zPgAhEJEJEw4Dxg51mcx9lxOODoFujg2dxTn70ZBQT6C13ahNkdilLKh7hyGXwT8IIxZmXNjcaYIhG5s74PGWMqROR3wDeAPzDXGLNdRGY4359tjNkpIl8DWwAH8JYxZtvZnswZyzkIpce9JhHsyyigW1Q4AboYjVLKg1xJBH8F0qpeiEgoEGOMSTLGfN/QB40xi4HFJ22bfdLrfwL/dDnixpS2yXr0mkSQT/+OrewOQynlY1y59PwI62q9SqVzW9OXthn8gyD6TDpDuUdJeSXJx4rooT2GlFIe5koiCHCOAwDA+TzIfSF5UNpmaNcPAuw/nQOZhTgM2nVUKeVxriSCTBG5puqFiEwGstwXkocYA0c2eU210IEsq8dQj2hNBEopz3KljWAG8L6IvIo1NiAFqHPgV5OSmwwluV6TCHKKygGIirD/7kQp5VtOmwiMMfuBUSISAYgxJt/9YXlA2mbr0eZJ5qoUllYAEB5s/3gGpZRvcanUEZErgf5ASNXyicaY/3VjXO6XthnEH9r1tzsSwEoEIhAW5G93KEopH+PKgLLZwBTgPqyqoZuALm6Oy/3SNkG7vrYuSVlTQWkF4UEBuk6xUsrjXGksHmOM+RWQY4x5ChhN7akjmp7qhuIhdkdSrbC0gvBgvRtQSnmeK4mgxPlYJCIdgXKgm/tC8oD8NCjK8pqGYoDC0kptH1BK2cKVkucL5wIy/wQ2YM0g+qY7g3K7zF3WY0w/e+OooaC0gghNBEopGzRY8jgXpPneGJMLfCwii4AQY0yeJ4Jzm6Jj1mN4I09pfQ4KnW0ESinlaQ1WDRljHMC/arwubfJJAKA4x3oMbW1vHDUUlFZo1ZBSyhautBEsEZEbpDl1Z/HCRFBYVkGLEE0ESinPc6XkeRgIBypEpASrC6kxxrR0a2TuVHQMglqAf6DdkVSzGou115BSyvNcGVnc/NZNLM6BMO+5GwCtGlJK2ee0JY+IjKtr+8kL1TQpxce8qlqovNJBWYWDCG0sVkrZwJWS5/c1nocAI4H1wAS3ROQJxTkQ2sbuKKrpPENKKTu5UjV0dc3XItIZeM5tEXlCcQ608p7B0QXORKDjCJRSdjibxXFTgQGNHYhHFR2DMG+6I6gE9I5AKWUPV9oIXsEaTQxW4hgCbHZjTO7lcFjrEHhRG0FBddWQ9hpSSnmeK5egiTWeVwDzjTGr3BSP+5XmgXF4ZRuBVg0ppezgSsnzX6DEGFMJICL+IhJmjClyb2hu4o2DybSxWCllI1faCL4HQmu8DgW+c084HlDkTARe1EagjcVKKTu5kghCjDEFVS+cz8PcF5Kb6R2BUkrV4koiKBSRYVUvRGQ4UOy+kNys2DnzqDe1EZRV9RrSxmKllOe5cgn6IPCRiBxxvu6AtXRl0+SFdwQFpRUE+gvBAZoIlFKe58qAsnUi0gfojTXh3C5jTLnbI3OXqrUIQlrZG0cNhTrPkFLKRq4sXn8vEG6M2WaM2QpEiMg97g/NTYpzrCTg7z0Fb4EuSqOUspErbQS/ca5QBoAxJgf4jdsicjcvm3AOrDsC7TGklLKLK4nAr+aiNCLiDwS5LyQ387IJ50DXIlBK2cuVy9BvgA9FZDbWVBMzgK/cGpU7FXnfHUFBqa5OppSyjyulzx+B6cDdWI3FG7F6DjVNxTnQtofdUdRSWFpBh1YhdoehlPJRp60aci5gvxY4ACQAE4Gdbo7Lfby0jUB7DSml7FJvIhCRXiLyFxHZCbwKpAAYYy4yxrzqysFFZJKI7BaRfSLyaAP7jRCRShG58UxP4Iw4KqEkz+vaCAq0sVgpZaOGSp9dwA/A1caYfQAi8pCrB3Y2Kr8GXIK1hsE6EfncGLOjjv3+gdUW4V7FudajF90RGGMoLNPGYqWUfRqqGroBOAosE5E3RWQiVhuBq0YC+4wxB4wxZcACYHId+90HfAxknMGxz06x9004V1rhoNJhtGpIKWWbehOBMWahMWYK0AdYDjwExIjILBG51IVjx+KsTnJKdW6rJiKxwHXA7IYOJCLTRSRRRBIzMzNd+Op6VM8z5D13BDrzqFLKbq40FhcaY943xlwFdAI2AfXW99dQ192DOen1i8Afq9Y6aCCGOcaYBGNMQnR0tAtfXY/qeYa8546geuZRHVmslLLJGZU+xphjwBvOn9NJBWquEN8JOHLSPgnAAud4tSjgChGpMMZ8eiZxuaxqnqHQSLcc/mwU6BTUSimbubP0WQfEi0g34DAwFbil5g7GmG5Vz0XkHWCR25IAeGUbQdXC9Vo1pJSyi9tKH2NMhYj8Dqs3kD8w1xizXURmON9vsF3ALYqPgfhBsHfNPAq6FoFSyj5uvQw1xiwGFp+0rc4EYIy53Z2xAM6ZRyPBz5UpljxDG4uVUnbznhLRE7xwniFdplIpZTffSgTFOV7VPgDaWKyUsp+PJQJvvCNwrlccpG0ESil7+Fgi8MK1CMoqCAn0I8Dft/4plFLew7dKn6Icr7sj0AnnlFJ2851EUFkOZfle10agU1ArpezmO4mgenoJ77ojKNSF65VSNtNEYDOtGlJK2c13EkGR9808CrpwvVLKfr6TCLxwniHQNgKllP18JxGEtYE+V0FEe7sjqUWrhpRSdvOdEihulPXjZfSOQCllN9+5I/BCDkfVesWaCJRS9tFEYKOi8qq1CLSxWCllH00ENtKZR5VS3kATgY3yS3QtAqWU/TQR2EgXrldKeQNNBDbSqiGllDfQRGAjXaZSKeUNNBHYqLBMF65XStlPE4GNCkqruo/qHYFSyj6aCGyUlV+KCLQMDbQ7FKWUD9NEYKO9GfnEtQkjJFCrhpRS9tFEYKO96QXEt2thdxhKKR+nicAmZRUODmYV0ismwu5QlFI+ThOBTZKyC6lwGOI1ESilbKaJwCZ70wsAtGpIKWU7TQQ22ZOej59Az3Z6R6CUspcmAptojyGllLfQRGCTvekF9NRqIaWUF9BEYAPtMaSU8iaaCGxQ1WOoV4zeESil7OfWRCAik0Rkt4jsE5FH63j/FyKyxfmzWkQGuzMeb7EnPR9Au44qpbyC2xKBiPgDrwGXA/2AaSLS76TdDgIXGmMGAX8D5rgrHm+yN70AP4Ee0ZoIlFL2c+cdwUhgnzHmgDGmDFgATK65gzFmtTEmx/lyLdDJjfF4De0xpJTyJu5MBLFASo3Xqc5t9bkL+MqN8XiNPekFxGv7gFLKS7gzEUgd20ydO4pchJUI/ljP+9NFJFFEEjMzMxsxRM8rq3CQlFVIvA4kU0p5CXcmglSgc43XnYAjJ+8kIoOAt4DJxpjsug5kjJljjEkwxiRER0e7JVhP0R5DSilv485EsA6IF5FuIhIETAU+r7mDiMQBnwC/NMbscWMsXkN7DCmlvI3b1kg0xlSIyO+AbwB/YK4xZruIzHC+Pxv4C9AWeF1EACqMMQnuiskb7Dmarz2GlFJexa2L5RpjFgOLT9o2u8bzXwO/dmcM3mZTah69YlpojyGllNfQkcUe5HAYNiXnMDSutd2hKKVUNbfeEajaDmQVcrykgqFxkXaHopRblZeXk5qaSklJid2h+JyQkBA6depEYGCgy5/RROBBG5OtsXPDNBGoZi41NZUWLVrQtWtXnO1/ygOMMWRnZ5Oamkq3bt1c/pxWDXnQhuRcWoQE0D1KG4pV81ZSUkLbtm01CXiYiNC2bdszvhPTROBBG5NzGNI5Ej8//c+hmj9NAvY4m9+7JgIPKSitYE96PsO0oVgp5WU0EXjIltRcHAZtKFbKA8aPH88333xTa9uLL77IPffc0+BnEhMT63wvMzOTwMBA3njjjUaN01toIvCQjcm5AAzpHGlrHEr5gmnTprFgwYJa2xYsWMC0adPO6ngfffQRo0aNYv78+Y0RntfRXkMesjE5l+7R4USGBdkdilIe9dQX29lx5HijHrNfx5b89er+9b5/44038sQTT1BaWkpwcDBJSUkcOXKE888/n7vvvpt169ZRXFzMjTfeyFNPPXXa75s/fz7/+te/uOWWWzh8+DCxsdZEyvPmzWPmzJmICIMGDeI///kP6enpzJgxgwMHDgAwa9YsxowZ0zgn7iZ6R+ABxhg2peQwtLO2DyjlCW3btmXkyJF8/fXXgHU3MGXKFESEp59+msTERLZs2cKKFSvYsmVLg8dKSUnh6NGjjBw5kptvvpkPPvgAgO3bt/P000+zdOlSNm/ezEsvvQTA/fffz4UXXsjmzZvZsGED/fvXn7C8hd4ReEBqTjFZBWXaPqB8UkNX7u5UVT00efJkFixYwNy5cwH48MMPmTNnDhUVFaSlpbFjxw4GDRpU73EWLFjAzTffDMDUqVO56667ePjhh1m6dCk33ngjUVFRALRp0waApUuXMm/ePAD8/f1p1aqVO0+zUWgi8IANzoFkmgiU8pxrr72Whx9+mA0bNlBcXMywYcM4ePAgM2fOZN26dbRu3Zrbb7/9tH3u58+fT3p6Ou+//z4AR44cYe/evRhjmk0XWa0a8oBV+7IIDfSnt65BoJTHREREMH78eO68887qRuLjx48THh5Oq1atSE9P56uvGl4Ucffu3RQWFnL48GGSkpJISkriscceY8GCBUycOJEPP/yQ7GxrGZVjx44BMHHiRGbNmgVAZWUlx483bvuIO2gicLMjucUs3HiY64bFEuCvv26lPGnatGls3ryZqVOnAjB48GCGDh1K//79ufPOOxk7dmyDn58/fz7XXXddrW033HAD8+fPp3///jz++ONceOGFDB48mIcffhiAl156iWXLljFw4ECGDx/O9u3b3XNyjUiMqXP1SK+VkJBg6uvr642e+HQrH6xLYfnvLyI2MtTucJTyiJ07d9K3b1+7w/BZdf3+RWR9feu96CWqGx3JLeaDdSncnNBZk4BSymtpInCj15fvA+Cei3raHIlSStVPE4Gb6N2AUqqp0ETgJrNX7Af0bkAp5f00EbhBfkk5/12fyjWDY/VuQCnl9TQRuMGnGw9TVFbJr0Z3sTsUpZQ6LU0EjcwYw3/WHmJgbCsG60yjSnlcdnY2Q4YMYciQIbRv357Y2Njq12VlZQ1+NjExkfvvv/+039HYk8g98MADxMbG4nA4GvW4rtIpJhrZzwePsSe9gOduqH/uEqWU+7Rt25ZNmzYB8OSTTxIREcEjjzxS/X5FRQUBAXUXfQkJCSQk1NnVvpbVq1c3SqwADoeDhQsX0rlzZ1auXMn48eMb7diu0kTQyN77KZmWIQFcPbij3aEo5R2+ehSObm3cY7YfCJc/6/Lut99+O23atGHjxo0MGzaMKVOm8OCDD1JcXExoaChvv/02vXv3Zvny5cycOZNFixbx5JNPkpyczIEDB0hOTubBBx+svluIiIigoKCA5cuX8+STTxIVFcW2bdsYPnw47733HiLC4sWLefjhh4mKimLYsGEcOHCARYsWnRLbsmXLGDBgAFOmTGH+/PnViaC+6azrmvr6XGkiOEf7MvIpKK1kYGwrjhWW8fW2NH45qiuhQf52h6aUqmHPnj189913+Pv7c/z4cVauXElAQADfffcdf/rTn/j4449P+cyuXbtYtmwZ+fn59O7dm7vvvpvAwMBa+2zcuJHt27fTsWNHxo4dy6pVq0hISOC3v/0tK1eupFu3bg0uiDN//nymTZvG5MmT+dOf/kR5eTmBgYHV01kvXLiQyspKCgoKqqe+XrVqFVFRUdXzG50rTQTnYNvhPG5+Yw1FZZW0DgsktnUo5ZWGX4yKszs0pbzHGVy5u9NNN92Ev791gZaXl8dtt93G3r17ERHKy8vr/MyVV15JcHAwwcHBtGvXjvT0dDp16lRrn5EjR1ZvGzJkCElJSURERNC9e3e6desGWHMezZkz55Tjl5WVsXjxYl544QVatGjBeeedx5IlS7jyyivrnM563rx5dU59fa40EZyl1Jwi7nhnHa3DgnjqmnjW7M9m5d5MLusfQ4/oCLvDU0qdJDw8vPr5n//8Zy666CIWLlxIUlJSvfXywcHB1c/9/f2pqKhwaR9X53D7+uuvycvLY+DAgQAUFRURFhbGlVdeWef+7pr6WnsNnYW8onLueHsdJeWVvH3HCG5K6MzzU4aw7vGLeeOXp29oUkrZKy8vr3q5yXfeeafRj9+nTx8OHDhAUlISQPWqZiebP38+b731VvUU1wcPHmTJkiUUFRXVOZ11fVNfnyufuSNYsSeTvy/a0SjHyi0uJ7eojHfvHEmvGmsMNJdFKpRq7v7whz9w22238fzzzzNhwoRGP35oaCivv/46kyZNIioqipEjR56yT1FREd988w1vvPFG9bbw8HDOP/98vvjiC1566SWmT5/Ov//9b/z9/Zk1axajR4+unvra39+foUOHNkoi85lpqNcfyuHfPx5olBgE4YbhsUzoE9Mox1OqudFpqKGgoICIiAiMMdx7773Ex8fz0EMPeeS7z3Qaap+5IxjepTXDuwy3OwyllI948803effddykrK2Po0KH89re/tTukevlMIlBKKU966KGHPHYHcK60sVgp5RZNrdq5uTib37tbE4GITBKR3SKyT0QereN9EZGXne9vEZFh7oxHKeUZISEhZGdnazLwMGMM2dnZhISEnNHn3FY1JCL+wGvAJUAqsE5EPjfG1Oy6czkQ7/w5D5jlfFRKNWGdOnUiNTWVzMxMu0PxOSEhIacMejsdd7YRjAT2GWMOAIjIAmAyUDMRTAbmGeuyYa2IRIpIB2NMmhvjUkq5WWBgYPWoWuX93Fk1FAuk1Hid6tx2pvsgItNFJFFEEvUKQymlGpc7E0Fdo6tOrjB0ZR+MMXOMMQnGmITo6OhGCU4ppZTFnYkgFehc43Un4MhZ7KOUUsqN3DayWEQCgD3AROAwsA64xRizvcY+VwK/A67AaiR+2Rhz6ljs2sfNBA6dZVhRQNZZfrYp88Xz9sVzBt88b188Zzjz8+5ijKmzSsVtjcXGmAoR+R3wDeAPzDXGbBeRGc73ZwOLsZLAPqAIuMOF45513ZCIJNY3xLo588Xz9sVzBt88b188Z2jc83bryGJjzGKswr7mttk1nhvgXnfGoJRSqmE6slgppXycryWCU5cI8g2+eN6+eM7gm+fti+cMjXjeTW4aaqWUUo3L1+4IlFJKnUQTgVJK+TifSQSnmwm1ORCRziKyTER2ish2EXnAub2NiHwrInudj63tjrWxiYi/iGwUkUXO175wzpEi8l8R2eX8Nx/tI+f9kPPve5uIzBeRkOZ23iIyV0QyRGRbjW31nqOIPOYs23aLyGVn+n0+kQhqzIR6OdAPmCYi/eyNyi0qgP8xxvQFRgH3Os/zUeB7Y0w88L3zdXPzALCzxmtfOOeXgK+NMX2AwVjn36zPW0RigfuBBGPMAKwxSlNpfuf9DjDppG11nqPz//hUoL/zM687yzyX+UQioMZMqMaYMqBqJtRmxRiTZozZ4Hyej1UwxGKd67vO3d4FrrUlQDcRkU7AlcBbNTY393NuCYwD/g1gjCkzxuTSzM/bKQAIdc5eEIY1LU2zOm9jzErg2Emb6zvHycACY0ypMeYg1gDdBmdoOJmvJAKXZjltTkSkKzAU+AmIqZra2/nYzsbQ3OFF4A+Ao8a25n7O3YFM4G1nldhbIhJOMz9vY8xhYCaQDKQBecaYJTTz83aq7xzPuXzzlUTg0iynzYWIRAAfAw8aY47bHY87ichVQIYxZr3dsXhYADAMmGWMGQoU0vSrQ07LWS8+GegGdATCReRWe6Oy3TmXb76SCHxmllMRCcRKAu8bYz5xbk4XkQ7O9zsAGXbF5wZjgWtEJAmrym+CiLxH8z5nsP6mU40xPzlf/xcrMTT3874YOGiMyTTGlAOfAGNo/ucN9Z/jOZdvvpII1gHxItJNRIKwGlY+tzmmRiciglVnvNMY83yNtz4HbnM+vw34zNOxuYsx5jFjTCdjTFesf9elxphbacbnDGCMOQqkiEhv56aJWKv/NevzxqoSGiUiYc6/94lYbWHN/byh/nP8HJgqIsEi0g1r6d+fz+jIxhif+MGa5XQPsB943O543HSO52PdEm4BNjl/rgDaYvUy2Ot8bGN3rG46//HAIufzZn/OwBAg0fnv/SnQ2kfO+ylgF7AN+A8Q3NzOG5iP1QZSjnXFf1dD5wg87izbdgOXn+n36RQTSinl43ylakgppVQ9NBEopZSP00SglFI+ThOBUkr5OE0ESinl4zQRKHUSEakUkU01fhptxK6IdK05o6RS3sCti9cr1UQVG2OG2B2EUp6idwRKuUhEkkTkHyLys/Onp3N7FxH5XkS2OB/jnNtjRGShiGx2/oxxHspfRN50zqm/RERCbTsppdBEoFRdQk+qGppS473jxpiRwKtYs57ifD7PGDMIeB942bn9ZWCFMWYw1jxA253b44HXjDH9gVzgBreejVKnoSOLlTqJiBQYYyLq2J4ETDDGHHBO7nfUGNNWRLKADsaYcuf2NGNMlIhkAp2MMaU1jtEV+NZYi4sgIn8EAo0xf/fAqSlVJ70jUOrMmHqe17dPXUprPK9E2+qUzTQRKHVmptR4XON8vhpr5lOAXwA/Op9/D9wN1Wsqt/RUkEqdCb0SUepUoSKyqcbrr40xVV1Ig0XkJ6yLqGnObfcDc0Xk91irht3h3P4AMEdE7sK68r8ba0ZJpbyKthEo5SJnG0GCMSbL7liUakxaNaSUUj5O7wiUUsrH6R2BUkr5OE0ESinl4zQRKKWUj9NEoJRSPk4TgVJK+bj/D54lJyOf1mddAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([i for i in range(epochs)], history.history['val_acc'], label='Val Acc')\n",
    "plt.plot([i for i in range(epochs)], history.history['acc'], label='Training Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
